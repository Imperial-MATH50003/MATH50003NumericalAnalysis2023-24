

# Integration

One possible definition for an integral is the limit of a Riemann sum, for example:
$$
  ∫_0^1 f(x) {\rm d}x = \lim_{n → ∞} {1 \over n} ∑_{k=1}^n f(k/n).
$$
This suggests an algorithm known as the _(right-sided) rectangular rule_
for approximating an integral: choose $n$ large so that
$$
  ∫_0^1 f(x) {\rm d}x ≈ {1 \over n} ∑_{k=1}^n f(k/n).
$$
In the lab we explore practical implementation of this approximation, and observe that
the error in approximation is bounded by $C/n$ for some constant $C$. This can be expressed using
"Big-O" notation:
$$
∫_0^1 f(x) {\rm d}x = {1 \over n} ∑_{k=1}^n f(k/n) + O(1/n).
$$

In these notes we consider the "Analysis" part of "Numerical Analysis": we want to _prove_ the
convergence rate of the approximation, including finding an explicit expression for the constant $C$.

To tackle this question we consider the error incurred on a single "rectangle", then sum up the errors on rectangles.

Now for a secret. There are only so many tools available in analysis (especially at this stage of your career), and 
one can make a safe bet that the right tool in any analysis proof is either (1) integration-by-parts, (2) geometric series
or (3) Taylor series. In this case we use (1):

**Lemma (rect. rule on one panel)**
Assuming $f$ is differentiable we have
$$
∫_0^h f(x) {\rm d}x = h f(0) +  δ_h
$$
where $|δ_h| ≤ M h^2$
for $M = \sup_{0 ≤ x ≤ h}|f'(x)|$.

**Proof**
We write
$$
∫_0^h f(x) {\rm d}x = ∫_0^h (x)' f(x)  {\rm d}x = [x f(x)]_0^h - ∫_0^h x f'(x) {\rm d} x
= h f(h) + \underbrace{-∫_0^h x f'(x) {\rm d} x}_{δ_h}.
$$
Recall that we can bound the absolute value of an integral by the sepremum of the integrand
times the width of the integration interval:
$$
|∫_a^b g(x) {\rm d} x| ≤ (b-a) \sup_{0 ≤ x ≤ h}|g(x)|.
$$
The lemma thus follows since
$$
|∫_0^h x f'(x) {\rm d} x| ≤ h \sup_{0 ≤ x ≤ h}|x f'(x)| ≤ M h^2.
$$
∎


