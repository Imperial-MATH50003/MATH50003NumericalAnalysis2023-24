**Numerical Analysis MATH50003 (2023‚Äì24) Revision Sheet**


**Problem 1(a)** State which real number is represented by an IEEE 16-bit floating point number (with $œÉ = 15, Q = 5$, and $S = 10$) with bits
$$
{\tt 1\ 01000\ 0000000001}
$$

**SOLUTION**
The sign bit is 1 so the answer is negative. The exponent bits correspond to
$$
q = 2^3 = 8
$$
The significand is
$$
(1.0000000001)_2 = 1 + 2^{-10}
$$
So this represents
$$
-2^{8-œÉ} (1 + 2^{-10}) = - 2^{-7} (1 + 2^{-10})
$$

**END**

**Problem 1(b)**  How are the following real numbers rounded to the nearest $F_{16}$?
$$
1/2, 1/2 + 2^{-12}, 3 + 2^{-9} + 2^{-10}, 3 + 2^{-10} + 2^{-11}.
$$

**SOLUTION**
$1/2$ is already a float. We have
$$
1/2 + 2^{-12} = (0.100000000001)_2 = 2^{-1} (1.00000000001)_2
$$
This is exactly at the midpoint so is rounded down so the last bit is 0, that is, it is rounded
to $1/2$.  Next we have
$$
3 + 2^{-9}  + 2^{-10} = (11.0000000011)_2 = 2(1.10000000011)_2.
$$
This time we are are exactly at the midpoint but we round up so the last bit is 0 giving us
$$
2(1.100000001)_2 = 3 + 2^{-8}.
$$
Finally,
$$
3 + 2^{-10} + 2^{-11} = 2(1.100000000011)_2
$$
This we round up since we are above the midpoint giving us
$$
2(1.1000000001)_2 = 3 + 2^{-9}.
$$
**END**

**Problem 2(a)** Consider a Lower triangular matrix with floating point entries:
$$
L = \begin{bmatrix}
‚Ñì_{11} \\
 ‚Ñì_{21} & ‚Ñì_{22} \\
 ‚ãÆ & ‚ã± & ‚ã± \\
 ‚Ñì_{n1} & ‚ãØ & ‚Ñì_{n,n-1} & ‚Ñì_{nn}
 \end{bmatrix} ‚àà F_{œÉ,Q,S}^{n √ó n}
$$
and a vector $ùê± \in F_{œÉ,Q,S}^{n}$, where $F_{œÉ,Q,S}$ is a set of floating-point numbers.
Denoting matrix-vector multiplication implemented using floating point arithmetic as
$$
ùêõ := {\tt lowermul}(L,ùê±)
$$
express the entries $b_k := {\bf e}_k^‚ä§ ùêõ$  in terms of $‚Ñì_{kj}$ and $x_k := {\bf e}_k^‚ä§ ùê±$, 
using rounded floating-point operations $‚äï$ and $‚äó$.

**SOLUTION**
$$
b_k = ‚®Å_{j=1}^k (‚Ñì_{kj} ‚äó x_j)
$$

**END**

**Problem 2(b)** Assuming all operations involve normal floating numbers, show that your approximation has the form
$$
L ùê± = {\tt lowermul}(L, ùê±) + ùõú
$$
where, for $œµ_{\rm m}$ denoting machine epsilon and $E_{n,œµ}:= {n œµ \over 1-nœµ}$ and assuming $n œµ_{\rm m} < 2$,
$$
\| ùõú \|_1 ‚â§   2E_{n,œµ_{\rm m}/2}   \|L\|_1 \| ùê± \|_1.
$$
Here we use  the matrix norm $\| A \|_1 := \max_j ‚àë_{k=1}^n |a_{kj}|$
and the vector norm $\| ùê± \|_1 := ‚àë_{k=1}^n |x_k|$. You may use the fact that
$$
x_1 ‚äï ‚ãØ ‚äï x_n = x_1 +  ‚ãØ + x_n + œÉ_n
$$
where
$$
|œÉ_n| ‚â§ \| ùê± \|_1 E_{n-1,œµ_{\rm m}/2}.
$$


**SOLUTION**

We have
$$
b_k = (‚®Å_{j=1}^k ‚Ñì_{kj} ‚äó x_j) =
(‚®Å_{j=1}^k ‚Ñì_{kj} x_j (1 + Œ¥_j)) =
(‚àë_{j=1}^k ‚Ñì_{kj} x_j (1 + Œ¥_j)) + œÉ_k
$$
where
$$
|œÉ_k| ‚â§ M_k E_{k-1,œµ_{\rm m}/2}
$$
for
$$
M_k := ‚àë_{j=1}^k  |‚Ñì_{kj}| |x_j| |1 + Œ¥_j| ‚â§ 2 ‚àë_{j=1}^k  |‚Ñì_{kj}| |x_j|.
$$
Thus
$$
b_k = ùêû_k^‚ä§ L ùê± + \underbrace{‚àë_{j=1}^{k} ‚Ñì_{kj} x_j Œ¥_j + œÉ_k}_{Œµ_k}.
$$
where
$$
|Œµ_k| ‚â§ ‚àë_{j=1}^{k} |‚Ñì_{kj}| |x_j| (|Œ¥_j| + 2 E_{k-1,œµ_{\rm m}/2})
‚â§  2E_{k,œµ_{\rm m}/2} ‚àë_{j=1}^{k} |‚Ñì_{kj}| |x_j|
$$
where we use
$$
\begin{align*}
 (|Œ¥_j| + 2 E_{k-1,œµ_{\rm m}/2}) &‚â§ {œµ_{\rm m} \over 2} + 2 {(k-1) {œµ_{\rm m} / 2} \over 1-(k-1){œµ_{\rm m}/ 2}} \cr
 &= {œµ_{\rm m}/2 - (k-1)œµ_{\rm m}^2/4 +  2(k-1) {œµ_{\rm m} / 2} \over 1-(k-1){œµ_{\rm m}/ 2}} \cr
 &‚â§ {2k {œµ_{\rm m} / 2} \over 1-k{œµ_{\rm m}/ 2}} = 2E_{k,œµ_{\rm m}/ 2}.
\end{align*}
$$
We then have using $E_{k,œµ_{\rm m}/ 2} ‚â§ E_{n,œµ_{\rm m}/ 2}$,
$$
\meeq{
\| ùõú \|_1 = ‚àë_{k=1}^n |Œµ_k| ‚â§ 2E_{n,œµ_{\rm m}/2} ‚àë_{k=1}^n ‚àë_{j=1}^k |‚Ñì_{kj}| |x_j | \ccr
=  2E_{n,œµ_{\rm m}/2} ‚àë_{j=1}^n  |x_j | ‚àë_{k=1}^{n-j+1} |‚Ñì_{kj}| ‚â§ 2E_{n,œµ_{\rm m}/2}  ‚àë_{j=1}^n  |x_j | \|L\|_1 \ccr
= 2E_{n,œµ_{\rm m}/2} \|L\|_1 \| ùê±\|_1.
}
$$

**END**



**Problem 3** What is the dual extension of square-roots? I.e. what should $\sqrt{a + b œµ}$ equal assuming $a > 0$?

**SOLUTION**
$$
\sqrt{a + b œµ} = \sqrt{a} + {b \over 2 \sqrt{a}}  œµ
$$
**END**





**Problem 4** Use the Cholesky factorisation to determine
whether the following matrix is symmetric positive definite:
$$
\begin{bmatrix} 2 & 2 & 1  \\
2 & 3 & 2\\
1 & 2 & 2
\end{bmatrix}
$$

**SOLUTION**

Here $Œ±_1 = 2$ and $ùêØ = [2,1]$ giving us
$$
\begin{align*}
A_2 &= \begin{bmatrix}
3&2\\
2&2
\end{bmatrix}-{1 \over 2} \begin{bmatrix} 2 \\ 1 \end{bmatrix}\begin{bmatrix} 2 & 1 \end{bmatrix}\\
&=
\begin{bmatrix}
1&1\\
1&3/2
\end{bmatrix}
\end{align*}
$$
Thus $Œ±_2 = 1$ and $ùêØ = [1]$ giving us
$$
\begin{align*}
A_3 &= [3/2 - 1] = [1/2]
\end{align*}
$$
As $Œ±_3 = 1/2 > 0$ we know a Cholesky decomposition exists hence $A$ is SPD. In particular we have computed
$A = LL^‚ä§$ where
$$
L = \begin{bmatrix}
\sqrt{2} \\
\sqrt{2} & 1 \\
1/\sqrt{2} & 1 & 1/\sqrt{2}
\end{bmatrix}
$$

**END**

**Problem 5** Use reflections to determine the entries of an orthogonal matrix $Q$ such that
$$
Q \begin{bmatrix} 2 \\ 1 \\ 2 \end{bmatrix} =  \begin{bmatrix} -3 \\ 0 \\ 0 \end{bmatrix}.
$$

**SOLUTION**

$$
\begin{align*}
ùê± &:= [2,1,2], \| ùê± \| = 3\\
ùê≤ &:= \|ùê±\| ùêû_1 + ùê± = [5,1,2], \| ùê≤ \| = \sqrt{30} \\
ùê∞ &:= ùê≤ / \| ùê≤ \| = [5,1,2] /  \sqrt{30} \\
Q &:= I - 2ùê∞ ùê∞^‚ä§ = I - {1 \over 15} \begin{bmatrix}5 \\ 1 \\ 2 \end{bmatrix} [5 1 2] = I - {1 \over 15} \begin{bmatrix} 25 & 5 & 10 \\5 & 1 & 2 \\ 10 & 2 & 4 \end{bmatrix} \\
&= {1 \over 15} \begin{bmatrix} -10 & -5 & -10 \\ -5 & 14 & -2 \\ -10 & -2 & 11 \end{bmatrix}
\end{align*}
$$

**END**





**Problem 6** For the function $f(Œ∏) = \sin 3 Œ∏$, state explicit formulae for its Fourier coefficients
$$
\hat f_k := {1 \over 2œÄ} \int_0^{2œÄ} f(Œ∏) {\rm e}^{-{\rm i} k Œ∏} {\rm d}Œ∏
$$
and  their discrete approximation:
$$
\hat f_k^n := {1 \over n} \sum_{j=0}^{n-1} f(Œ∏_j) {\rm e}^{-{\rm i} k Œ∏_j}.
$$
for _all_ integers $k$, $n = 1,2,‚Ä¶$, where $Œ∏_j = 2œÄ j/n$.

**SOLUTION**

We have
$$
f(Œ∏) = \sin 3 Œ∏ = { \exp(3 i Œ∏) \over 2} -  { \exp(-3 i Œ∏) \over 2 i}
$$
hence $\hat f_3 = 1/(2i) \hat f_{-3} = -1/(2i)$ and $\hat f_k = 0$ otherwise. Thus we have:
$$
\begin{align*}
\hat f_k^1 &= \sum_{k=-‚àû}^‚àû \hat f_k = \hat f_{-3} + \hat f_3 = 0, \\
\hat f_{2k}^2 &= 0, \hat f_{2k+1}^2 = \hat f_{-3} + \hat f_3 = 0, \\
\hat f_{3k}^3 &= \hat f_{-3} + \hat f_3 = 0, \hat f_{3k+1}^3 = \hat f_{3k-1}^3 = 0, \\
\hat f_{4k}^4 &= \hat f_{4k+2}^4 = 0, \hat f_{4k+1}^4 = \hat f_{-3} = -1/(2i), \hat f_{4k+3}^4 = \hat f_{3} = 1/(2i) \\
\hat f_{5k}^5 &= \hat f_{5k+1}^5 = \hat f_{5k+4}^5,  \hat f_{5k+2}^5 = \hat f_{-3} = -1/(2i),  \hat f_{5k+3}^5 = \hat f_{3} = 1/(2i), \\
\hat f_{6k}^6 &= \hat f_{6k+1}^6 = \hat f_{6k+2}^6 = \hat f_{6k+4}^6 = \hat f_{6k+5}^6,  \hat f_{6k+3}^5 = \hat f_{-3} + \hat f_{3} = 0
\end{align*}
$$
For $n > 6$ we have
$$
\hat f_{-3+nk}^n =  \hat f_{-3} = -{1 \over 2i},\hat f_{3+nk}^n =  \hat f_{3} = {1 \over 2i}
$$
and all other $\hat f_k^n = 0$.

**END**






**Problem 7** Consider orthogonal polynomials
$$
H_n(x) = 2^n x^n + O (x^{n-1})
$$
as $x ‚Üí ‚àû$ and $n = 0, 1, 2, ‚Ä¶$,  orthogonal with respect to the inner product
$$
\langle f, g \rangle = \int_{-‚àû}^‚àû f(x) g(x) w(x) {\rm d}x, \qquad w(x) = \exp(-x^2)
$$
Construct $H_0(x)$, $H_1(x)$, $H_2(x)$ and hence show that $H_3(x) = 8x^3-12x$. You may use without proof the formulae
$$
\int_{-‚àû}^‚àû w(x) {\rm d}x = \sqrt{œÄ}, \int_{-‚àû}^‚àû x^2 w(x) {\rm d}x = \sqrt{œÄ}/2,
\int_{-‚àû}^‚àû x^4 w(x) {\rm d}x = 3\sqrt{œÄ}/4.
$$

**SOLUTION**

Because $w(x) = w(-x)$ we know that $a_k$ is zero. We further know that $H_0(x) = 1$ with $\|H_0\|^2 = \sqrt{œÄ}$
 and $H_1(x) = 2x$ with
$$
\| H_1 \|^2 = 4 ‚à´_{-‚àû}^‚àû x^2 w(x) {\rm d}x = 2 \sqrt{œÄ}.
$$

We have
$$
 x H_1(x) = c_0 H_0(x) + H_2(x)/2
$$
where
$$
c_0 = {‚ü® x H_1(x), H_0(x) ‚ü© \over \|H_0\|^2 } = {\sqrt{œÄ}  \over \sqrt{œÄ}} = 1
$$
Hence $H_2(x) = 2 x H_1(x) - H_0(x) = 4x^2-2$, which satisfies
$$
\|H_2\|^2 = 16 ‚à´_{-‚àû}^‚àû x^4 w(x) {\rm d } x - 16‚à´_{-‚àû}^‚àû x^2 w(x) {\rm d}x + 4 ‚à´_{-‚àû}^‚àû  w(x) {\rm d}x =
(12 -8 + 4) \sqrt{œÄ} = 8 \sqrt{œÄ}.
$$
We further have
$$
‚ü® x H_2(x), H_1(x) ‚ü© =  ‚à´_{-‚àû}^‚àû (8x^4 - 4 x^2) w(x) {\rm d} x = (6 -2) \sqrt{œÄ} = 4 \sqrt{œÄ}
$$
Finally we have
$$
 x H_2(x) = c_1 H_1(x) + H_3(x)/2
$$
where
$$
c_1 = {‚ü® x H_2(x), H_1(x) ‚ü© \over \|H_1\|^2 } = { 4 \sqrt{œÄ}  \over 2 \sqrt{œÄ}} = 2
$$
Hence
$$
H_3(x) = 2x H_2(x) - 4 H_1(x) = 8x^3 - 12x.
$$



**END**



**Problem 8(a)** Derive the 3-point Gauss quadrature formula
$$
\int_{-‚àû}^‚àû f(x) \exp(-x^2) {\rm d}x ‚âà w_1 f(x_1) + w_2 f(x_2) + w_3 f(x_3)
$$
with analytic expressions for $x_j$ and $w_j$.

**SOLUTION**

We know $x_k$ are the roots of $H_3(x) = 8x^3 - 12x$ hence we have $x_2 = 0$ and the other roots satisfy
$$
2x^2 - 3 = 0,
$$
i.e., $x_1 = -\sqrt{3/2}$ and $x_2 = \sqrt{3/2}$. To deduce the weights the easiest approach is to use Lagrange
interpolation. An alternative is to orthonormalise. Note the Jacobi matrix satisfies
$$
x [H_0 | H_1 | H_2 | H_3 | ‚Ä¶] = [H_0 | H_1 | H_2 | H_3 | ‚Ä¶] \underbrace{\begin{bmatrix} 0 & 1  \\
                                                                    1/2 & 0 & 2 \\
                                                                       & 1/2 & 0 &  ‚ã±\\
                                                                          && 1/2 & ‚ã± \\
                                                                                &&& ‚ã± \end{bmatrix}}_X
$$
To find $q_k = d_k H_k$, orthonormalised versions of Hermite, we need to choose $d_k$ to symmetrise $X$,
that is for $D = {\rm diag}(d_0,d_1,‚Ä¶)$ we have
$$
x [q_0 | q_1 | ‚Ä¶] = x [H_0 | H_1 | ‚Ä¶] D = [H_0 | H_1 | ‚Ä¶] X D = [q_0 | q_1 | ‚Ä¶] D^{-1} X D
$$
where
$$
D^{-1} X D = \begin{bmatrix}                                                 0 & d_1/d_0  \\
                                                                    d_0/(2d_1) & 0 & 2d_2/d_1 \\
                                                                    & d_1/(2d_2) & 0 &  ‚ã±\\
                                                                        && d_2/(2d_3) & ‚ã± \\
                                                                     &&& ‚ã± \end{bmatrix}
$$
Note $d_0 = 1/\sqrt{‚à´_{-‚àû}^‚àû \exp(-x^2) {\rm d} x } = 1/œÄ^{1/4}$
then we have
$$
\begin{align*}
d_0^2 &= 2 d_1^2 ‚áí d_1 = 1/(\sqrt{2} œÄ^{1/4}) \\
d_1^2 &= 4 d_2^2 ‚áí d_2 = 1/(2\sqrt{2} œÄ^{1/4})
\end{align*}
$$
We thus have
$$
\meeq{
w_1 = {1 \over q_0(-\sqrt{3/2})^2 + q_1(-\sqrt{3/2})^2 + q_2(-\sqrt{3/2})^2} =
{1 \over d_0^2 + 4d_1^2 (3/2) + d_2^2 (6 - 2)^2} = {\sqrt{œÄ} \over 6} \ccr
w_2 = {1 \over q_0(0)^2 + q_1(0)^2 + q_2(0)^2} =
{1 \over d_0^2 + d_2^2 (2)^2} = {2\sqrt{œÄ} \over  3} \ccr
w_3 = w_1 = {\sqrt{œÄ} \over 6}.
}
$$


**END**



**Problem 8(b)** Compute the 2-point and 3-point Gaussian quadrature rules associated with $w(x) = 1$ on $[-1,1]$.

**SOLUTION**

For the weights $w(x) = 1$, the orthogonal polynomials of degree $‚â§ 3$ are the Legendre polynomials,
$$
\begin{align*}
	P_0(x) = 1, \\
	P_1(x) = x, \\
	P_2(x) = \frac{1}{2}(3x^2  - 1), \\
	P_3(x) = \frac{1}{2}(5x^3 - 3x)
\end{align*}
$$
which can be found from, e.g, the Rodriguez formula or by direct construction.
We can normalise each to get $q_j(x) = P_j(x)/\|P_j\|$, with $\|P_j\|^2 = \int_{-1}^1 P_j^2 dx$. This gives,
$$
\begin{align*}
	q_0(x) &= \frac{1}{\sqrt{2}}, \\
	q_1(x) &= \sqrt{\frac{3}{2}}x, \\
	q_2(x) &= \sqrt{\frac{5}{8}}(3x^2  - 1), \\
	q_3(x) &= \sqrt{\frac{7}{8}}(5x^3 - 3x).
\end{align*}
$$
For the first part we use the roots of $P_2(x)$ which are $ùê± = \left\{¬± \frac{1}{\sqrt{3}}\right\}$. The weights are,
$$
w_j = \frac{1}{Œ±_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2} = \frac{1}{\frac{1}{2}+\frac{3}{2}x_j^2},
$$
where $Œ±_j$ is the same as in III.6 Lemma 2,
so that,
$$
w_1 = w_2 = 1,
$$
and the Gaussian Quadrature rule is,
$$
Œ£_2^w[f] = f\left(-\frac{1}{\sqrt{3}}\right) + f\left(\frac{1}{\sqrt{3}}\right)
$$
For the second part, we use the roots of $P_3(x)$ which are $ùê± = \left\{0, ¬± \sqrt{\frac{3}{5}} \right\}$. The weights are then,
$$
w_j = \frac{1}{Œ±_j^2} = \frac{1}{q_0(x_j)^2 + q_1(x_j)^2 + q_2(x_j)^2} = \frac{1}{\frac{9}{8} -\frac{9}{4}x_j^2 + \frac{45}{8}x_j^4 }
$$
Giving us,
$$
\begin{align*}
	w_1 = w_3 = \frac{1}{\frac{9}{8} - \frac{9}{4}\frac{3}{5} + \frac{45}{8}\frac{9}{25}} &= \frac{5}{9} \\
	w_2 &= \frac{8}{9}
\end{align*}
$$
Then the Gaussian Quadrature rule is,
$$
Œ£_3^w[f] = \frac{1}{9} \left[5f\left(-\sqrt\frac{3}{5}\right) +8f(0) + 5f\left(\sqrt\frac{3}{5}\right) \right]
$$

**END**



**Problem 9** Solve Problem 4(b) from PS8 using **Lemma 12 (discrete orthogonality)** with
$w(x) = 1/\sqrt{1-x^2}$ on $[-1,1]$. That is, use the connection of $T_n(x)$ with $\cos n Œ∏$ to
show that the Discrete Cosine Transform
$$
C_n := \begin{bmatrix}
\sqrt{1/n} \\
 & \sqrt{2/n} \\
 && ‚ã± \\
 &&& \sqrt{2/n}
 \end{bmatrix}
\begin{bmatrix}
    1 & ‚ãØ & 1\\
    \cos Œ∏_1 & ‚ãØ & \cos Œ∏_n \\
    ‚ãÆ & ‚ã± & ‚ãÆ \\
    \cos (n-1)Œ∏_1 & ‚ãØ & \cos (n-1)Œ∏_n
\end{bmatrix}
$$
for $Œ∏_j = œÄ(j-1/2)/n$ is an orthogonal matrix.

**SOLUTION**


By the Lemma 3 (Discrete Orthogonality), we have,
$$
\begin{align*}
	Œ£_{n}^w[q_lq_m] = \frac{œÄ}{n}\sum_{j=1}^n q_l(x_j)q_m(x_j) = Œ¥_{lm}, \\
	\sum_{j=1}^n q_l(x_j)q_m(x_j) = \frac{n}{œÄ}Œ¥_{lm},
\end{align*}
$$
By the previous question, for the weight $w(x) = \frac{1}{\sqrt{1-x^2}}$ we have $q_0(x_j) = \frac{1}{\sqrt{œÄ}}$, $q_k(x_j) = \sqrt{\frac{2}{œÄ}}\cos(k Œ∏_j).$
For $l = m = 0$ then we have,
$$
\begin{align*}
	\frac{1}{œÄ}\sum_{j=1}^n \cos(l Œ∏_j)\cos(m Œ∏_j) =\sum_{j=1}^nq_l(x_j)q_m(x_j) =  \frac{n}{œÄ}Œ¥_{lm} = \frac{n}{œÄ} \\
	\Rightarrow \frac{1}{n}\sum_{j=1}^n \cos(l Œ∏_j)\cos(m Œ∏_j) = 1\
\end{align*}
$$
Now, for $l = m ‚â† 0$, we have,
$$
\begin{align*}
	\frac{2}{œÄ}\sum_{j=1}^n \cos(l Œ∏_j)\cos(m Œ∏_j) =\sum_{j=1}^nq_l(x_j)q_m(x_j) =  \frac{n}{œÄ}Œ¥_{lm} = \frac{n}{œÄ} \\
	\Rightarrow \frac{1}{n}\sum_{j=1}^n \cos(l Œ∏_j)\cos(m Œ∏_j) = \frac{1}{2}\
\end{align*}
$$
Finally, for $l ‚â† m$, we have,
$$
C_{lm}\sum_{j=1}^n\cos(l Œ∏_j)\cos(m Œ∏_j) = \sum_{j=1}^nq_l(x_j )q_m(x_j) = \frac{n}{œÄ}Œ¥_{lm} = 0,
$$
for some constant $C_{lm} ‚â† 0$ which is $\frac{1}{œÄ}$ if $l = 0$ or $m = 0$ and $\frac{2}{œÄ}$ otherwise (it doesn't matter what it is so long as it is not 0). Therefore, for $l ‚â† m$ we have,
$$
\frac{1}{n}\sum_{j=1}^n \cos(l Œ∏_j)\cos(m Œ∏_j) = 0
$$

**END**
